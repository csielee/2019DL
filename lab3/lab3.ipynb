{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import RetinopathyDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.models\n",
    "import pyprind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Found 28099 images...\n",
      "> Found 7025 images...\n"
     ]
    }
   ],
   "source": [
    "train_dataset = RetinopathyDataset('./data', 'train')\n",
    "test_dataset = RetinopathyDataset('./data', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    '''\n",
    "    x = (in, H, W) -> conv2d -> (out, H, W) -> conv2d -> (out, H, W) + x\n",
    "    '''\n",
    "    expansion = 1\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, stride=1, kernel_size=3, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        padding = int(kernel_size/2)\n",
    "        self.activation = nn.ReLU(inplace=True)\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels, out_channels, \n",
    "                kernel_size=kernel_size, padding=padding, stride=stride, bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            self.activation,\n",
    "            nn.Conv2d(\n",
    "                out_channels, out_channels, \n",
    "                kernel_size=kernel_size, padding=padding, bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "        self.downsample = downsample\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.block(x)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "        \n",
    "        out += residual\n",
    "        out = self.activation(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class BottleneckBlock(nn.Module):\n",
    "    '''\n",
    "    x = (in, H, W) -> conv2d(1x1) -> conv2d -> (out, H, W) -> conv2d(1x1) -> (out*4, H, W) + x \n",
    "    '''\n",
    "    expansion = 4\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, stride=1, kernel_size=3, downsample=None):\n",
    "        super(BottleneckBlock, self).__init__()\n",
    "        padding = int(kernel_size/2)\n",
    "        self.activation = nn.ReLU(inplace=True)\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            self.activation,\n",
    "            nn.Conv2d(\n",
    "                out_channels, out_channels,\n",
    "                kernel_size=kernel_size, stride=stride, padding=padding, bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            self.activation,\n",
    "            nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels * self.expansion),\n",
    "        )\n",
    "        self.downsample = downsample\n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.block(x)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "        \n",
    "        out += residual\n",
    "        out = self.activation(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes, start_in_channels=64):\n",
    "        super(ResNet, self).__init__()\n",
    "        \n",
    "        self.current_in_channels = start_in_channels\n",
    "        \n",
    "        self.first = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                3, self.current_in_channels,\n",
    "                kernel_size=7, stride=2, padding=3, bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(self.current_in_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "        )\n",
    "        \n",
    "        self.layers = layers\n",
    "        channels = self.current_in_channels\n",
    "        for i, l in enumerate(layers):\n",
    "            setattr(self, 'layer'+str(i+1), \n",
    "                    self._make_layer(block, channels, l, stride=(2 if i!=0 else 1) ))\n",
    "            channels*=2\n",
    "        \n",
    "        #self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(self.current_in_channels, num_classes)\n",
    "            \n",
    "    def _make_layer(self, block, in_channels, blocks, stride=1):\n",
    "        downsample=None\n",
    "        if stride != 1 or self.current_in_channels != in_channels * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    self.current_in_channels, in_channels * block.expansion,\n",
    "                    kernel_size = 1, stride=stride, bias=False\n",
    "                ),\n",
    "                nn.BatchNorm2d(in_channels * block.expansion)\n",
    "            )\n",
    "        \n",
    "        layers = []\n",
    "        layers.append(block(self.current_in_channels, in_channels, stride=stride, downsample=downsample))\n",
    "        self.current_in_channels = in_channels * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.current_in_channels, in_channels))\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.first(x)\n",
    "        #print(x.shape)\n",
    "        for i in range(len(self.layers)):\n",
    "            x = getattr(self, 'layer'+str(i+1))(x)\n",
    "            #print(x.shape)\n",
    "        x = self.avgpool(x)\n",
    "        # flatten\n",
    "        #print(x.shape)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PretrainResNet(nn.Module):\n",
    "    def __init__(self, num_classes, num_layers):\n",
    "        super(PretrainResNet, self).__init__()\n",
    "        \n",
    "        pretrained_model = torchvision.models.__dict__[\n",
    "            'resnet{}'.format(num_layers)](pretrained=True)\n",
    "        \n",
    "        self.conv1 = pretrained_model._modules['conv1']\n",
    "        self.bn1 = pretrained_model._modules['bn1']\n",
    "        self.relu = pretrained_model._modules['relu']\n",
    "        self.maxpool = pretrained_model._modules['maxpool']\n",
    "\n",
    "        self.layer1 = pretrained_model._modules['layer1']\n",
    "        self.layer2 = pretrained_model._modules['layer2']\n",
    "        self.layer3 = pretrained_model._modules['layer3']\n",
    "        self.layer4 = pretrained_model._modules['layer4']\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(\n",
    "            pretrained_model._modules['fc'].in_features, num_classes\n",
    "        )\n",
    "                \n",
    "        del pretrained_model\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        # print(x.shape)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet18(pre_train=False):\n",
    "    if pre_train:\n",
    "        return PretrainResNet(num_classes=5, num_layers=18)\n",
    "    return ResNet(BasicBlock, layers=[2,2,2,2], num_classes=5)\n",
    "def ResNet50(pre_train=False):\n",
    "    if pre_train:\n",
    "        return PretrainResNet(num_classes=5, num_layers=50)\n",
    "    return ResNet(BottleneckBlock, layers=[3,4,6,3], num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showAccuracy(title='', accline=[75, 82], **kwargs):\n",
    "    fig = plt.figure(figsize=(8,4.5))\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy(%)')\n",
    "    \n",
    "    for label, data in kwargs.items():\n",
    "        plt.plot(\n",
    "            range(1, len(data)+1), data, \n",
    "            '--' if 'test' in label else '-', \n",
    "            label=label\n",
    "        )\n",
    "    \n",
    "    plt.legend(\n",
    "        loc='best', bbox_to_anchor=(1.0, 1.0, 0.2, 0),\n",
    "        fancybox=True, shadow=True\n",
    "    )\n",
    "    \n",
    "    if accline:\n",
    "        plt.hlines(accline, 1, len(data)+1, linestyles='dashed', colors=(0,0,0,0.8))\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalModels(models, test_loader, testing_mode=False):\n",
    "    test_correct = {key:0.0 for key in models}\n",
    "    bar = pyprind.ProgPercent(len(test_loader.dataset), title=\"Testing epoch : \")\n",
    "    for model in models.values():\n",
    "        model.train(testing_mode)\n",
    "    with torch.no_grad():\n",
    "        for idx, data in enumerate(test_loader):\n",
    "            x, y = data\n",
    "            inputs = x.to(device)\n",
    "            labels = y.to(device)\n",
    "        \n",
    "            for key, model in models.items():\n",
    "                outputs = model.forward(inputs)\n",
    "        \n",
    "                test_correct[key] += (\n",
    "                    torch.max(outputs, 1)[1] == labels.long().view(-1)\n",
    "                ).sum().item()\n",
    "            \n",
    "            bar.update(test_loader.batch_size)\n",
    "            #clear_output(wait=True)\n",
    "            #print('Testing batch : {:.3f} %'.format(\n",
    "            #    ((idx+1)*test_loader.batch_size*100) / len(test_loader.dataset)\n",
    "            #))\n",
    "        \n",
    "    return test_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runModels(\n",
    "    models, epoch_size, batch_size, learning_rate, \n",
    "    optimizer = optim.SGD, optimizer_option = {'momentum':0.9, 'weight_decay':5e-4}, \n",
    "    criterion = nn.CrossEntropyLoss(),\n",
    "    show = True, testing_mode=False\n",
    "):\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "    \n",
    "    Accs = {\n",
    "    **{key+\"_train\" : [] for key in models},\n",
    "    **{key+\"_test\" : [] for key in models}\n",
    "    }\n",
    "    \n",
    "    x_index = []\n",
    "    \n",
    "    optimizers = {\n",
    "        key: optimizer(value.parameters(), lr=learning_rate, **optimizer_option) \n",
    "        for key, value in models.items()\n",
    "    }\n",
    "    for epoch in range(epoch_size):\n",
    "        bar = pyprind.ProgPercent(len(train_dataset), title=\"Training epoch : \")\n",
    "        \n",
    "        train_correct = {key:0.0 for key in models}\n",
    "        test_correct = {key:0.0 for key in models}\n",
    "        # training multiple model\n",
    "        for model in models.values():\n",
    "            model.train()\n",
    "        \n",
    "        for idx, data in enumerate(train_loader):\n",
    "            x, y = data\n",
    "            inputs = x.to(device)\n",
    "            labels = y.to(device).long().view(-1)\n",
    "        \n",
    "            for optimizer in optimizers.values():\n",
    "                optimizer.zero_grad()\n",
    "        \n",
    "            for key, model in models.items():\n",
    "                outputs = model.forward(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                \n",
    "                cur_correct = (\n",
    "                    torch.max(outputs, 1)[1] == labels\n",
    "                ).sum().item()\n",
    "            \n",
    "                train_correct[key] += cur_correct\n",
    "        \n",
    "            for optimizer in optimizers.values():\n",
    "                optimizer.step()\n",
    "            \n",
    "            bar.update(batch_size)\n",
    "            #clear_output(wait=True)\n",
    "            #print('Training batch : {:.3f} %'.format(((idx+1)*batch_size*100) / len(train_dataset)))\n",
    "        \n",
    "        # testing multiple model\n",
    "        test_correct = evalModels(\n",
    "            models, test_loader, \n",
    "            testing_mode=testing_mode\n",
    "        )\n",
    "\n",
    "        for key, value in train_correct.items():\n",
    "            Accs[key+\"_train\"] += [(value*100.0) / len(train_dataset)]\n",
    "    \n",
    "        for key, value in test_correct.items():\n",
    "            Accs[key+\"_test\"] += [(value*100.0) / len(test_dataset)]\n",
    "         \n",
    "        if show:\n",
    "            clear_output(wait=True)\n",
    "            showAccuracy(\n",
    "                title='Epoch [{:4d}]'.format(epoch + 1),\n",
    "                **Accs\n",
    "            )\n",
    "        \n",
    "        # epoch end\n",
    "        torch.cuda.empty_cache()\n",
    "        save_model(models)\n",
    "    return Accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "models = {\n",
    "    \"ResNet18\" : ResNet18().to(device),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Training & Testing\n",
    "Accs = runModels(models, epoch_size=1, batch_size=4, learning_rate=1e-3, show=False)\n",
    "showAccuracy(\n",
    "    title='ResNet18',\n",
    "    **Accs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __save_model(model_name, model, root):\n",
    "    if not os.path.isdir(root):\n",
    "        os.mkdir(root)\n",
    "    p = os.path.join(root, '{}-params.pkl'.format(model_name))\n",
    "    torch.save(model.state_dict(), p)\n",
    "    return p\n",
    "\n",
    "def save_model(models, root='./model'):\n",
    "    p = {}\n",
    "    for k, m in models.items():\n",
    "        p[k] = __save_model(k, m, root)\n",
    "    return p\n",
    "\n",
    "def __load_model(model_name, model, root):\n",
    "    p = os.path.join(root, '{}-params.pkl'.format(model_name))\n",
    "    if not os.path.isfile(p):\n",
    "        raise AttributeError(\n",
    "            \"No model parameters file for {}!\".format(model_name)\n",
    "        )\n",
    "    paras = torch.load(p)\n",
    "    model.load_state_dict(paras)\n",
    "\n",
    "def load_model(models, root='./model'):\n",
    "    for k, m in models.items():\n",
    "        __load_model(k, m, root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
